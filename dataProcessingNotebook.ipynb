{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Jupyter notebook file that prepares and standardizes data in advance of the main calculation and score\n",
    "\n",
    "\n",
    "## will require the key steps.\n",
    "### Main car data records:\n",
    "\n",
    "1.) combining all car manufacturers into the same database\n",
    "2.) highlighting null values\n",
    "3.) standardizing formatting accross columns in centralized 'used car data' csv\n",
    "4.) standardizing datatype for cost to be float\n",
    "\n",
    "### preparing maintenance costs to match car data\n",
    "\n",
    "1.) renaming columns\n",
    "\n",
    "data cleaning and formatting\n",
    "merging maintenance costs into central DB\n",
    "\n",
    "\n",
    "### preparing ratings to match car data\n",
    "data cleaning and formatting\n",
    "merging car ratings into central DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key imports\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /opt/anaconda3/lib/python3.9/site-packages (0.25.0)\r\n",
      "Requirement already satisfied: Levenshtein==0.25.0 in /opt/anaconda3/lib/python3.9/site-packages (from python-Levenshtein) (0.25.0)\r\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from Levenshtein==0.25.0->python-Levenshtein) (3.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all CSV files into a central CSV for processing\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where your CSV files are located\n",
    "pathToExistingCSVs = './Datasets/Provided_Datasets/used-car-dataset-challenge/Used_Car_Data_(incl mpg)/*.csv'\n",
    "\n",
    "\n",
    "# Define the output file where you want to combine all CSVs\n",
    "output_file = './Datasets/Processed_Data/used_car_data_combined.csv'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Clear the output file content before writing\n",
    "open(output_file, 'w').close()\n",
    "\n",
    "# Get a list of all CSV files in the directory, in alphabetical order based on brand\n",
    "csv_files = glob.glob(pathToExistingCSVs)\n",
    "csv_files = sorted(csv_files, key=lambda x: x.split('/')[-1])\n",
    "\n",
    "print(csv_files)\n",
    "\n",
    "# Initialize a variable to store all CSV headers (to ensure they are the same across files, plus the new \"brand\" column)\n",
    "headers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correcting mismatched header for Hyundai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyundaiDF = pd.read_csv('./Datasets/Provided_Datasets/used-car-dataset-challenge/Used_Car_Data_(incl mpg)/hyundai.csv')\n",
    "hyundaiDF.rename(columns={'tax(Â£)': 'tax'}, inplace=True)\n",
    "hyundaiDF.to_csv('./Datasets/Provided_Datasets/used-car-dataset-challenge/Used_Car_Data_(incl mpg)/hyundai.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the output file in write mode\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as f_out:\n",
    "    writer = csv.writer(f_out)\n",
    "\n",
    "    # Process each file in turn\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            # Extract brand name from the file name\n",
    "            brand_name = os.path.basename(file).replace('.csv', '')\n",
    "\n",
    "            with open(file, newline='', encoding='utf-8') as f_in:\n",
    "                reader = csv.reader(f_in)\n",
    "                header = next(reader)  # Read the header row\n",
    "\n",
    "                # If it's the first file, add \"brand\" to the headers list and write the header\n",
    "                if not headers:\n",
    "                    headers = ['brand'] + header\n",
    "                    writer.writerow(headers)\n",
    "                else:\n",
    "                    # catch here to make sure all files have similar structure\n",
    "                    assert headers[1:] == header, f\"Headers have a mismatch in the manufacturer: {file} with {header}\"\n",
    "\n",
    "\n",
    "                # Write the data rows with the \"brand\" column\n",
    "                for row in reader:\n",
    "                    writer.writerow([brand_name] + row)\n",
    "        except Exception as e:\n",
    "            print(f\"Theres an error with {file}: {e}\")\n",
    "\n",
    "            \n",
    "print(f\"All CSV files have been combined into {output_file}\")\n",
    "print(f\"all unique headers are: {headers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datasets/Processed_Data/used_car_data_combined.csv')\n",
    "\n",
    "collective_null_values = df.isnull().sum().sum()\n",
    "print(f\"There are {collective_null_values} null entries present in combined set.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abnormal values check\n",
    "\n",
    "checking to verify any incorrect classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting Mercedes name\n",
    "unique_brands = df['brand'].unique()\n",
    "print(unique_brands)\n",
    "\n",
    "df['brand'] = df['brand'].replace(r'merc', 'mercedes', regex=True)\n",
    "\n",
    "unique_brands = df['brand'].unique()\n",
    "print(unique_brands)\n",
    "\n",
    "# Transmission class checks\n",
    "unique_transmissions = df['transmission'].unique()\n",
    "unique_transmissionsOtherCount = (df['transmission'] == 'Other').sum()\n",
    "print(f\"Unique transmissions: {unique_transmissions}.\")\n",
    "print(f\"'Other count': {unique_transmissionsOtherCount}\")\n",
    "print(f\"Dropping 'other' class in transmission due to input error\\n\\n\")\n",
    "\n",
    "cars_to_drop_transmission = df[df['transmission'] == 'Other'].index\n",
    "df.drop(cars_to_drop_transmission, inplace=True)\n",
    "\n",
    "\n",
    "##### Fuel class checks\n",
    "unique_fuelType = df['fuelType'].unique()\n",
    "unique_fuelTypeCount = (df['fuelType'] == 'Other').sum()\n",
    "print(f\"Unique fuel type: {unique_fuelType}.\")\n",
    "print(f\"'Other' fuel count: {unique_fuelTypeCount}\")\n",
    "\n",
    "cars_to_drop_fuel = df[df['fuelType'] == 'Other'].index\n",
    "df.drop(cars_to_drop_fuel, inplace=True)\n",
    "print(f\"Dropping irregular fuel types for these entries.\\n\\n\")\n",
    "\n",
    "\n",
    "###### year range check\n",
    "current_unix_timestamp = datetime.datetime.now().timestamp()\n",
    "current_datetime = datetime.datetime.fromtimestamp(current_unix_timestamp)\n",
    "current_year = current_datetime.year\n",
    "\n",
    "\n",
    "oldest_car_value = df['year'].min()\n",
    "newest_car_value = df['year'].max()\n",
    "print(f\"Oldest car: {oldest_car_value}.\")\n",
    "print(f\"Newest car: {newest_car_value}.\")\n",
    "\n",
    "\n",
    "print(f\"Newest car entries that exceed current year and are likely entered in error, will drop from dataset\")\n",
    "cars_to_drop_year = df[df['year'] > current_year].index\n",
    "over_current_year = (df['year'] > current_year).sum()\n",
    "\n",
    "print(f\"number of cars being dropped due to exceeding {current_year}: {over_current_year}.\")\n",
    "df.drop(cars_to_drop_year, inplace=True)\n",
    "\n",
    "df['model'] = df['model'].str.lstrip()\n",
    "df.to_csv('./Datasets/Processed_Data/used_car_data_combined.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Maintainance costs CSV in advance of merger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenanceDF = pd.read_csv('./Datasets/Provided_Datasets/Used-car-dataset-challenge/Car_Maintenance_Costs.csv')\n",
    "print(maintenanceDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "combined_cars_df = pd.read_csv(r'Datasets/Processed_Data/used_car_data_combined.csv')\n",
    "maintenanceDF = pd.read_csv(r'Datasets/Provided_Datasets/used-car-dataset-challenge/Car_Maintenance_Costs.csv')\n",
    "\n",
    "\n",
    "#print(combined_cars_df.head())\n",
    "print(maintenanceDF.head())\n",
    "\n",
    "\n",
    "# Convert 'Make' column to lowercase and replace 'hyundi' with 'hyundai'. \n",
    "maintenanceDF['Make'] = maintenanceDF['Make'].str.lower().replace(r'hyundi', 'hyundai', regex=True)\n",
    "\n",
    "# Ensure 'MaintenanceCostYearly' is a float with two decimal places\n",
    "maintenanceDF['MaintenanceCostYearly'] = maintenanceDF['MaintenanceCostYearly'].astype(float).round(2)\n",
    "\n",
    "# Strip leading/trailing whitespace and convert 'Model' column to lowercase\n",
    "maintenanceDF['Model'] = maintenanceDF['Model'].str.title()\n",
    "\n",
    "\n",
    "# making all columns lowercase for future merger\n",
    "maintenanceDF.rename(columns={'Make': 'Make'.lower()}, inplace=True)\n",
    "maintenanceDF.rename(columns={'Model': 'Model'.lower()}, inplace=True)\n",
    "maintenanceDF.rename(columns={'Year': 'Year'.lower()}, inplace=True)\n",
    "\n",
    "print(maintenanceDF.head())\n",
    "maintenanceDF.to_csv('./Datasets/Processed_Data/Car_Maintenance_Costs_Sanitized.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'model' class prep.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenanceDF = pd.read_csv('./Datasets/Processed_Data/Car_Maintenance_Costs_Sanitized.csv')\n",
    "#print(maintenanceDF.head())\n",
    "\n",
    "\n",
    "# Function to get the best match for a given model\n",
    "def get_best_match(model, choices):\n",
    "    \n",
    "    if (model.lower() == 'ka') or (model.lower() == 'Ka'):\n",
    "        return ' KA'\n",
    "    \n",
    "    else:\n",
    "\n",
    "        match = process.extractOne(model, choices, scorer=process.fuzz.token_sort_ratio, score_cutoff=75)\n",
    "        # If a match is found with a score above the cutoff, return the matched model, else return the original\n",
    "        return match[0] if match else model\n",
    "\n",
    "\n",
    "\n",
    "# Strip leading/trailing whitespace and convert 'Model' column to lowercase\n",
    "maintenanceDF['model'] = maintenanceDF['model'].str.lower()\n",
    "maintenanceDF['model'] = maintenanceDF['model'].str.title()\n",
    "maintenanceDF['model'] = maintenanceDF['model'].str.strip()\n",
    "\n",
    "\n",
    "# Create a list of unique models from the combined_cars dataset for matching\n",
    "model_choices = combined_cars_df['model'].unique()\n",
    "\n",
    "# Replace 'Model' entries in df with the best match from combined_cars_df\n",
    "maintenanceDF['model'] = maintenanceDF['model'].apply(lambda x: get_best_match(x, model_choices))\n",
    "maintenanceDF['model'] = maintenanceDF['model'].str.lstrip()\n",
    "\n",
    "\n",
    "maintenanceDF.rename(columns={'make': 'brand'}, inplace=True)\n",
    "maintenanceDF.to_csv('./Datasets/Processed_Data/Car_Maintenance_Costs_Sanitized.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_models_maintenance = maintenanceDF['model'].unique()\n",
    "print(f'Maintenance DF has {len(unique_models_maintenance)} unique entries.')\n",
    "#print(unique_models_maintenance)\n",
    "\n",
    "unique_models_combined = combined_cars_df['model'].unique()\n",
    "print(f'Combined dataset DF has {len(unique_models_combined)} unique entries.')\n",
    "#print(unique_models_combined)\n",
    "\n",
    "\n",
    "unique_models_existing_set = set(unique_models_combined)\n",
    "unique_models_maintenance_set = set(unique_models_maintenance)\n",
    "\n",
    "unique_to_existing_only = unique_models_existing_set - unique_models_maintenance_set\n",
    "print(\"Entries only present in existing files: \")\n",
    "print(unique_to_existing_only)\n",
    "\n",
    "unique_to_maintenance_only = unique_models_maintenance_set - unique_models_existing_set\n",
    "print(\"Entries only present in maintenance files: \")\n",
    "print(unique_to_maintenance_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once all car models in Maintenance set acceptable, can merge into main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_car_data_DF = pd.read_csv('./Datasets/Processed_Data/used_car_data_combined.csv')\n",
    "maintenance_DF = pd.read_csv('./Datasets/Processed_Data/Car_Maintenance_Costs_Sanitized.csv')\n",
    "\n",
    "main_car_data_DF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF = pd.merge(main_car_data_DF, maintenance_DF[['brand', 'model', 'year', 'MaintenanceCostYearly']],\n",
    "                     on=['brand', 'model', 'year'],\n",
    "                     how='left')\n",
    "\n",
    "#combinedDF.head()\n",
    "combinedDF.to_csv('./Datasets/Processed_Data/used_car_data_combined.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carReviewsDF = pd.read_csv(r'Datasets/Provided_Datasets/used-car-dataset-challenge/Car_Reviews.csv')\n",
    "print(carReviewsDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing and merging ratings using same steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column titles to the ratings data and saving\n",
    "column_titles = ['brand', 'model', 'rating']\n",
    "ratingsDF = pd.read_csv(r'Datasets/Provided_Datasets/used-car-dataset-challenge/Car_Reviews.csv', header=None, names=column_titles)\n",
    "\n",
    "ratingsDF.to_csv('./Datasets/Processed_Data/Car_Reviews_Sanitized.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'brand' column to lowercase and replace 'hyundi' with 'hyundai'. \n",
    "ratingsDF['brand'] = ratingsDF['brand'].str.lower().replace(r'hyundi', 'hyundai', regex=True)\n",
    "# Also converting 'volkswagen' to 'vw' to match existing data.\n",
    "ratingsDF['brand'] = ratingsDF['brand'].replace(r'volkswagen', 'vw', regex=True)\n",
    "\n",
    "# Strip leading/trailing whitespace and convert 'Model' column to lowercase. Title gives first initial a capital\n",
    "ratingsDF['model'] = ratingsDF['model'].str.title()\n",
    "\n",
    "\n",
    "# making all columns lowercase for future merger\n",
    "ratingsDF.rename(columns={'brand': 'brand'.lower()}, inplace=True)\n",
    "ratingsDF.rename(columns={'model': 'model'.lower()}, inplace=True)\n",
    "\n",
    "ratingsDF.to_csv('./Datasets/Processed_Data/Car_Reviews_Sanitized.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratingsDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding abnormal values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding and removing incorrect brand name\n",
    "\n",
    "unique_brands_ratings = ratingsDF['brand'].unique()\n",
    "print(f'ratings DF has {len(unique_brands_ratings)} unique entries.')\n",
    "print(unique_brands_ratings)\n",
    "\n",
    "indices_to_drop = ratingsDF[ratingsDF['brand'] == 'make'].index\n",
    "ratingsDF.drop(indices_to_drop, inplace=True)\n",
    "\n",
    "unique_brands_ratings = ratingsDF['brand'].unique()\n",
    "print(f'ratings DF has {len(unique_brands_ratings)} unique entries.')\n",
    "print(unique_brands_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cars_df = pd.read_csv('./Datasets/Processed_Data/used_car_data_combined.csv')\n",
    "ratingsDF = pd.read_csv('Datasets/Processed_Data/Car_Reviews_Sanitized.csv')\n",
    "\n",
    "\n",
    "# Strip leading/trailing whitespace and convert 'Model' column to lowercase\n",
    "ratingsDF['model'] = ratingsDF['model'].str.lower()\n",
    "ratingsDF['model'] = ratingsDF['model'].str.title()\n",
    "ratingsDF['model'] = ratingsDF['model'].str.strip()\n",
    "\n",
    "# Create a list of unique models from the combined_cars dataset for matching\n",
    "#model_choices = combined_cars_df['model'].unique()\n",
    "#print(model_choices)\n",
    "\n",
    "#rating_choices = ratingsDF['model'].unique()\n",
    "#print(rating_choices)\n",
    "\n",
    "# Function to get the best match for a given model\n",
    "def get_best_match(model, choices):\n",
    "    \n",
    "    if (model.lower() == 'ka') or (model.lower() == 'Ka'):\n",
    "        return ' KA'\n",
    "    \n",
    "    else:\n",
    "        match = process.extractOne(model, choices, scorer=process.fuzz.token_sort_ratio, score_cutoff=75)\n",
    "        # If a match is found with a score above the cutoff, return the matched model, else return the original\n",
    "        return match[0] if match else model\n",
    "\n",
    "\n",
    "# Replace 'Model' entries in df with the best match from combined_cars_df\n",
    "ratingsDF['model'] = ratingsDF['model'].apply(lambda x: get_best_match(x, model_choices))\n",
    "ratingsDF['model'] = ratingsDF['model'].str.lstrip()\n",
    "\n",
    "#rating_choices = ratingsDF['model'].unique()\n",
    "#print(rating_choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_models_ratings = ratingsDF['model'].unique()\n",
    "print(f'ratings DF has {len(unique_models_ratings)} unique model entries.')\n",
    "print(unique_models_ratings)\n",
    "\n",
    "\n",
    "unique_models_combined = combined_cars_df['model'].unique()\n",
    "print(f'Combined dataset DF has {len(unique_models_combined)} unique model entries.')\n",
    "print(unique_models_combined)\n",
    "\n",
    "\n",
    "unique_models_existing_set = set(unique_models_combined)\n",
    "unique_models_ratings_set = set(unique_models_ratings)\n",
    "\n",
    "unique_to_existing_only = unique_models_existing_set - unique_models_ratings_set\n",
    "print(\"Entries only present in existing files: \")\n",
    "print(unique_to_existing_only)\n",
    "\n",
    "unique_to_ratings_only = unique_models_ratings_set - unique_models_existing_set\n",
    "print(\"Entries only present in ratings files: \")\n",
    "print(unique_to_ratings_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratingsDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF = pd.merge(main_car_data_DF, maintenance_DF[['brand', 'model', 'year', 'MaintenanceCostYearly']],\n",
    "                     on=['brand', 'model', 'year'],\n",
    "                     how='left')\n",
    "\n",
    "combinedDF.head()\n",
    "combinedDF.to_csv('./Datasets/Processed_Data/used_car_data_combined.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
